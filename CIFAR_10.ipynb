{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR 10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Mr1E6folYsoe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Scikit Learn - Extra Trees Classifier"
      ]
    },
    {
      "metadata": {
        "id": "VQK4yLZGZEHv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, import numpy, cifar10 from `keras.datasets`, and the `ExtraTreesClassifier` from sklearn."
      ]
    },
    {
      "metadata": {
        "id": "1HGHHVcbYX74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4399050-9fcb-47c3-827b-3b3c6db24bdd"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_AHBfTxsZSVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we import and format our data."
      ]
    },
    {
      "metadata": {
        "id": "iVE5JtVnYaVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "26ff88c6-1394-4b05-b3fc-4fec26bce18c"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "m_train, m_test = x_train.shape[0], x_test.shape[0]\n",
        "\n",
        "x_train, x_test = x_train.reshape(m_train, -1), x_test.reshape(m_test, -1)\n",
        "\n",
        "x_train = x_train / np.linalg.norm(x_train, ord=2, axis=1, keepdims=True)\n",
        "x_test = x_test / np.linalg.norm(x_test, ord=2, axis=1, keepdims=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 19s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MSQh2E59ZXIA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then. we initialize and train our classifier."
      ]
    },
    {
      "metadata": {
        "id": "ugPUrydxNPLa",
        "colab_type": "code",
        "outputId": "d5653a5b-66b2-4977-9678-83985fa0a531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "clf = ExtraTreesClassifier()\n",
        "\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
              "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=1, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
              "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "mQfN-VpYZdNH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And finally, test it out!"
      ]
    },
    {
      "metadata": {
        "id": "VKfy_NqtYdZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2d37cbc-87fa-47c4-f765-2aa1cb86bc3c"
      },
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "predictions = clf.predict(x_test)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  if(y_test[i]==predictions[i]):\n",
        "    count+=1\n",
        "    \n",
        "\n",
        "print((count/len(y_test))*100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MQWih2g2Zjul",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can see that this is a disappointingly low score. In the next section we will take a different approach to increase this."
      ]
    },
    {
      "metadata": {
        "id": "W8H_awECY3jG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keras and Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "ZMf962MRZt-K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to make a simple model with Keras and Tensorflow, we will import tensorflow and some things from keras as well."
      ]
    },
    {
      "metadata": {
        "id": "6tSLxdR-Yg_G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.constraints import maxnorm\n",
        "from PIL import Image\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SuNautz3b51C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, load in the data.\n"
      ]
    },
    {
      "metadata": {
        "id": "H2ls3z8NcALv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train,y_train), (x_test,y_test) = cifar10.load_data()\n",
        "\n",
        "new_X_train = x_train.astype('float32')\n",
        "new_X_test = x_test.astype('float32')\n",
        "new_X_train /= 255 \n",
        "new_X_test /= 255\n",
        "new_Y_train = np_utils.to_categorical(y_train)\n",
        "new_Y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aEUDzCviZ3IE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we create our model, compile it, and fit it to the data."
      ]
    },
    {
      "metadata": {
        "id": "kjcGPdFhYjrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "bd62ae63-797a-4255-ea0e-b2f6e2473a0e"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32,(3,3),input_shape=(32,32,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Conv2D(32,(3,3),input_shape=(32,32,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Flatten(),\n",
        "    Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(new_X_train,new_Y_train,epochs=3,batch_size=32)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "50000/50000 [==============================] - 14s 279us/step - loss: 1.4529 - acc: 0.4839\n",
            "Epoch 2/3\n",
            "50000/50000 [==============================] - 19s 373us/step - loss: 1.1091 - acc: 0.6159\n",
            "Epoch 3/3\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 0.9878 - acc: 0.6576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f23c7879208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "QilvxratZ-jN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we will store some data that allows us to use the model without needing to train it again."
      ]
    },
    {
      "metadata": {
        "id": "8qgeXu-gURmH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json_string = model.to_json()\n",
        "model.save_weights('model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bip_YkDVaIp2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we load in our model using the data we stored."
      ]
    },
    {
      "metadata": {
        "id": "vq821l9XXwSh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "model = model_from_json(json_string)\n",
        "model.load_weights('model_weights.h5')\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7hVOI92aN6P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, we test out this model!"
      ]
    },
    {
      "metadata": {
        "id": "yPGSttOgYqtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f6fa404-a892-413a-d54e-159074b2ffb5"
      },
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  if(y_test[i]==np.argmax(predictions[i])):\n",
        "    count+=1\n",
        "    \n",
        "\n",
        "print((count/len(y_test))*100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_kl1CyFsilRY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a significant increase in accuracy. If you want an even higher accuracy, train the model for more epochs, play around with hyperparameters, and add some layers!"
      ]
    }
  ]
}
